---
title: "Bike Sharing Analysis Report"
author: "Brian Boughton and Brian Tulimero"
date: "2023-02-04"
output: word_document
---
```{r}
pacman::p_load(pacman, dplyr,forecast,car,ROSE,rpart)
```

# Milestone 1

## Introduction
The data set used was collected by Hadi fanaee from the laboratory of Artificial Intelligence and Decision Support at the University of Porto in Portugal. The contains information around bike sharing. It consist of an entry number, date, year, season, month, day of the week, hour, and whether or not it was a weekend. It also contains information around weather like temperature, wind speed and, forecast. Lastly, it gives the amount of casual and registered bike borrows along the total number.

Our goal with this data is to make predictions of future rentals based on day information and predicted forecasts. There are a few unnecessary
variables in the dataset that have been removed like the instant number and date along with the casual and registered users because we are currently only interested in the overall users.

## Data Wrangling

### Importing data and setting needed categories to factors and removing the uneeded variables.
```{r}
pj.dt<-read.csv("hour.csv")
pj.df<-read.csv("hour.csv")
pj.df$season<- as.factor(pj.df$season)
pj.df$yr<- as.factor(pj.df$yr)
pj.df$mnth<- as.factor(pj.df$mnth)
pj.df$hr<- as.factor(pj.df$hr)
pj.df$holiday<- as.factor(pj.df$holiday)
pj.df$weekday<- as.factor(pj.df$weekday)
pj.df$workingday<- as.factor(pj.df$workingday)
pj.df$weathersit<- as.factor(pj.df$weathersit)
pj<-subset(pj.df, select = -c(instant, dteday,casual,registered))
```

The final data frame is called simply pj for project and there are other version of the dataset if needed.
Description of each feature:
* instant: record index
* dteday : date
* season : season (1:spring, 2:summer, 3:fall, 4:winter)
* yr : year (0: 2011, 1:2012)
* mnth : month ( 1 to 12)
* hr : hour (0 to 23)
* holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)
* weekday : day of the week
* workingday : if day is neither weekend nor holiday is 1, otherwise is 0.
* weathersit : 
* - 1: Clear, Few clouds, Partly cloudy, Partly cloudy
*	- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
*	- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
*	- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
* temp : Normalized temperature in Celsius. The values are divided to 41 (max)
* atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)
* hum: Normalized humidity. The values are divided to 100 (max)
* windspeed: Normalized wind speed. The values are divided to 67 (max)
* casual: count of casual users
* registered: count of registered users
* cnt: count of total rental bikes including both casual and registered


### Getting to understand the data.

```{r}
summary(pj)
#showing number of Entries and features
dim(pj)
#displaying the number of missing entries
sum(is.na(pj))
#showing numeric data features
names(select_if(pj, is.numeric))
#showing categorical data features
names(select_if(pj, is.factor))
```

We can see that the data consist of 13 different variables and 17,379 observations. There is not missing data entries found within the data. The numeric features are temp, atemp, hum, windspeed, and cnt. the categorical features are season, yr, mnth, hr, holiday, weekday, workingday, and weathersit.

```{r}
with(pj, plot(cnt~weekday))
with(pj, plot(cnt~season))
with(pj, plot(cnt~yr))
with(pj, plot(cnt~holiday))
with(pj, plot(cnt~mnth))
with(pj, plot(cnt~hr))
with(pj, plot(cnt~workingday))

```
The above boxplot shows that there are an extreme amount of outliars

### Model development

```{r}
(mean<-mean(pj$cnt))
(mean.spring<-mean(pj[pj$season == 1, 'cnt'], na.rm = TRUE))
(mean.summer<-mean(pj[pj$season == 2, 'cnt'], na.rm = TRUE))
(mean.fall<-mean(pj[pj$season == 3, 'cnt'], na.rm = TRUE))
(mean.winter<-mean(pj[pj$season == 4, 'cnt'], na.rm = TRUE))
```

```{r}
winsor<-function(cnt){
  #Defining the normal range
Q3<-quantile(cnt,0.75,na.rm = TRUE)
Q1<-quantile(cnt,0.25,na.rm = TRUE)
upper<-Q3+1.5*(Q3-Q1)
lower<-Q1-1.5*(Q3-Q1)
#replacing values that exceed upper and lower  normal ranges
winsor.cnt<-ifelse(cnt>upper,
                 upper, 
                 ifelse(cnt<lower,
                        lower,
                        cnt))
return(winsor.cnt)
}
#imputing cleaned data into raw data set.
pj$cnt<-winsor(pj$cnt)

```

```{r}
with(pj, plot(cnt~weekday))
```

The number outliars now has been lowered based on the unconditional mean

### Creating training and test data frames

```{r}
set.seed(1318)
#Randomly choosing 80% of the data set
train.rows<- sample(rownames(pj), dim(pj)[1]*0.8)
#Create the training set
train<-pj[train.rows,]
#Repeat for Test set
valid.rows<-setdiff(rownames(pj),train.rows)
valid<-pj[valid.rows,]
```

**Summaries**

```{r}
summary(train)
# dimensions of train data set
dim(train)
summary(valid)
# dimensions of valid data set
dim(valid)
```

### Creating a linear regression

```{r}
# Creating null model
null<-lm(cnt~1,data=train)
#Creating Full model
full<-lm(cnt~.,data=train)
#Using stepwise function to find the optimal variable configuration for the model
opti<-step(
    full,
    scope = list(upper = full, lower = null),
    direction = "both",
    trace = FALSE
  )
summary(opti)
```

```{r}
accuracy(opti$fitted.values, train$cnt)
pred <- predict(opti, newdata = valid)
accuracy(pred, valid$cnt)
```

### Creating a logistic Model


```{r}
#Creating binary values for cnt.
pj.2<-pj
#Finding the mean of the cnt data
mean<-mean(pj.2$cnt)
#replaceing values above or equal to mean with '1' and all below with '0'
pj.2$cnt<-with(pj.2, ifelse(cnt>=mean,1,0))

#getting total value of entries with value 1 and seeing the percentage.
sum(pj.2$cnt) # 7045 values were equal to or above the mean 
sum(pj.2$cnt)/length(pj.2$cnt) # These values make up about 40% of the data
```

```{r}
set.seed(1318)
#Randomly choosing 60% of the data set
train.rows<- sample(rownames(pj.2), dim(pj.2)[1]*0.6)
#Create the training set
train.2<-pj.2[train.rows,]
#Repeat for Test set
valid.rows<-setdiff(rownames(pj.2),train.rows)
valid.2<-pj.2[valid.rows,]
```


```{r}
# Creating null model
null2<-glm(cnt~1,data=train.2)
#Creating Full model
full2<-glm(cnt~.,data=train.2)
#Using stepwise function to find the optimal variable configuration for the model
opti2<-step(
    full2,
    scope = list(upper = full2, lower = null2),
    direction = "both",
    trace = FALSE, family = binomial
  )
summary(opti2)
```

```{r}
actual.train<-train.2$cnt
pred.train<-predict(opti2,train.2,type='response')
actual.valid<-valid.2$cnt
pred.valid<-predict(opti2,valid.2,type='response')
(conf.matrix1<-table(actual.train, pred.train>.5))
(conf.matrix2<-table(actual.valid, pred.valid>.5))
```


Accuracy, sensitivity, and specificity for training data
```{r}
#Accuracy
sum(diag(conf.matrix1))/nrow(train.2)
#sensitivity
conf.matrix1[2,2]/ sum(conf.matrix1[2,])
#specificity
conf.matrix1[1,1]/sum(conf.matrix1[1,])
```

Accuracy, sensitivity, and specificity for test data
```{r}
#Accuracy
sum(diag(conf.matrix2))/nrow(valid.2)
#sensitivity
conf.matrix2[2,2]/ sum(conf.matrix2[2,])
#specificity
conf.matrix2[1,1]/sum(conf.matrix2[1,])
```

```{r}
#Training AUC
roc.curve(response =actual.train, predicted = pred.train)
#Valid AUC
roc.curve(response =actual.valid, predicted = pred.valid)
```
